19/01/30 02:34:10 WARN Utils: Your hostname, VM_0_11_centos resolves to a loopback address: 127.0.0.1; using 172.16.0.11 instead (on interface eth0)
19/01/30 02:34:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
19/01/30 02:34:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "ERROR".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Spark context Web UI available at http://172.16.0.11:4041
Spark context available as 'sc' (master = local[*], app id = local-1548786859574).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0
      /_/
         
Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_191)
Type in expressions to have them evaluated.
Type :help for more information.

scala> System.out.println(System.getProperty("user.dir"))
/home/davidyu/stock/scripts/davidyu_stock/scripts/download/liutong_owner

scala> val work_dir=System.getProperty("user.dir")
work_dir: String = /home/davidyu/stock/scripts/davidyu_stock/scripts/download/liutong_owner

scala> val data_file="file://"+work_dir+"/all.csv"
data_file: String = file:///home/davidyu/stock/scripts/davidyu_stock/scripts/download/liutong_owner/all.csv

scala> 

scala> val table = "stock_dev.liutong_owner"
table: String = stock_dev.liutong_owner

scala> val sql1= s""" insert into table $table select * from data_tr"""
sql1: String = " insert into table stock_dev.liutong_owner select * from data_tr"

scala> println(sql1)
 insert into table stock_dev.liutong_owner select * from data_tr

scala> val sqlContext = new org.apache.spark.sql.hive.HiveContext(sc)
warning: there was one deprecation warning; re-run with -deprecation for details
sqlContext: org.apache.spark.sql.hive.HiveContext = org.apache.spark.sql.hive.HiveContext@2e895acb

scala> 

scala> val csv_data = spark.read.csv(data_file)
csv_data: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 5 more fields]

scala> csv_data.show()
+---+--------------------------+--------+------+----------+----------+------+
|_c0|                       _c1|     _c2|   _c3|       _c4|       _c5|   _c6|
+---+--------------------------+--------+------+----------+----------+------+
|  1|    深圳市建设投资控股公司|29798954|12.239|    国有股|2018-09-30|000011|
|  2|                    杜歆晔| 3880800| 1.594|  自然人股|2018-09-30|000011|
|  3|                      周群| 3115450| 1.280|  自然人股|2018-09-30|000011|
|  4|                    杜允丰| 2323000| 0.954|  自然人股|2018-09-30|000011|
|  5|                    高文仁| 1506000| 0.619|  自然人股|2018-09-30|000011|
|  6|                    杨耀初| 1410620| 0.579|  自然人股|2018-09-30|000011|
|  7|                      李京| 1176740| 0.483|  自然人股|2018-09-30|000011|
|  8|                    苏志芬| 1150000| 0.472|  自然人股|2018-09-30|000011|
|  9|                    麦富容| 1130500| 0.464|  自然人股|2018-09-30|000011|
| 10|武汉兴开源电力工程有限公司| 1100000| 0.452|境内法人股|2018-09-30|000011|
|  1|    深圳市建设投资控股公司|29798954|12.239|    国有股|2018-06-30|000011|
|  2|                    杜歆晔| 3880800| 1.594|  自然人股|2018-06-30|000011|
|  3|                      周群| 3115450| 1.280|  自然人股|2018-06-30|000011|
|  4|                    杜允丰| 2323000| 0.954|  自然人股|2018-06-30|000011|
|  5|                    杨耀初| 1410620| 0.579|  自然人股|2018-06-30|000011|
|  6|武汉兴开源电力工程有限公司| 1300000| 0.534|境内法人股|2018-06-30|000011|
|  7|                      李京| 1176740| 0.483|  自然人股|2018-06-30|000011|
|  8|                    麦富容| 1130500| 0.464|  自然人股|2018-06-30|000011|
|  9|                    陈丽英|  951521| 0.391|  自然人股|2018-06-30|000011|
| 10|                      王惠|  764481| 0.314|  自然人股|2018-06-30|000011|
+---+--------------------------+--------+------+----------+----------+------+
only showing top 20 rows


scala> csv_data.createOrReplaceTempView("data_tr")

scala> sqlContext.sql(sql1)
19/01/30 02:34:34 ERROR ObjectStore: Version information found in metastore differs 3.1.0 from expected schema version 1.2.0. Schema verififcation is disabled hive.metastore.schema.verification so setting version.
[Stage 2:>                                                          (0 + 1) / 1]                                                                                res4: org.apache.spark.sql.DataFrame = []

scala> 

scala> //csv_data.toDF().insertInto("day_history")

scala> 

scala> 

scala> 

scala> //select max(stock_date) as date from stock_dev.day_history;

scala> 

scala> 

scala> :quit
