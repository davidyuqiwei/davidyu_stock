2019-01-16 00:49:26 WARN  Utils:66 - Your hostname, VM_0_11_centos resolves to a loopback address: 127.0.0.1; using 172.16.0.11 instead (on interface eth0)
2019-01-16 00:49:26 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2019-01-16 00:49:27 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
2019-01-16 00:49:36 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2019-01-16 00:49:36 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
Spark context Web UI available at http://172.16.0.11:4042
Spark context available as 'sc' (master = local[*], app id = local-1547570976152).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.0
      /_/
         
Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_191)
Type in expressions to have them evaluated.
Type :help for more information.

scala> System.out.println(System.getProperty("user.dir"))
/home/davidyu/stock/scripts/davidyu_stock/scripts/download/day_history

scala> val work_dir=System.getProperty("user.dir")
work_dir: String = /home/davidyu/stock/scripts/davidyu_stock/scripts/download/day_history

scala> val data_file="file://"+work_dir+"/all.csv"
data_file: String = file:///home/davidyu/stock/scripts/davidyu_stock/scripts/download/day_history/all.csv

scala> 

scala> val sqlContext = new org.apache.spark.sql.hive.HiveContext(sc)
warning: there was one deprecation warning; re-run with -deprecation for details
sqlContext: org.apache.spark.sql.hive.HiveContext = org.apache.spark.sql.hive.HiveContext@1299fed3

scala> 

scala> val csv_data = spark.read.csv(data_file)
csv_data: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 6 more fields]

scala> csv_data.show()
+----------+-----+-----+-----+-----+-----------+-----+------+
|       _c0|  _c1|  _c2|  _c3|  _c4|        _c5|  _c6|   _c7|
+----------+-----+-----+-----+-----+-----------+-----+------+
|2019-01-14| 12.5|10.85| 11.4|12.07| 94126947.0|12.07|000070|
|2019-01-15|11.85|11.02| 11.5|11.22| 68836781.0|11.22|000070|
|2019-01-14| 3.18| 2.98|  3.1| 3.07| 40128958.0| 3.07|000533|
|2019-01-15| 3.05| 2.96| 2.99| 3.03| 28692791.0| 3.03|000533|
|2019-01-14| 3.07| 2.77|  2.8| 3.07|160427549.0| 3.07|000587|
|2019-01-15| 3.24| 2.98| 3.11| 3.13|212922980.0| 3.13|000587|
|2019-01-14|11.39|10.92|11.15|10.98| 75696474.0|10.98|000735|
|2019-01-15|11.35|10.57|10.95|11.23|112205560.0|11.23|000735|
|2019-01-14| 5.22| 5.02| 5.21| 5.08|131836146.0| 5.08|000750|
|2019-01-15| 5.29| 5.05| 5.08| 5.19|242667686.0| 5.19|000750|
|2019-01-14| 5.45| 5.22| 5.28| 5.31|  5446367.0| 5.31|000797|
|2019-01-15| 5.54| 5.22| 5.26| 5.39|  8128762.0| 5.39|000797|
|2019-01-14| 6.25|  5.7|  5.8| 6.12| 30508872.0| 6.12|000890|
|2019-01-15| 6.11| 5.75| 5.99| 6.01| 22808081.0| 6.01|000890|
|2019-01-14|10.84|10.65| 10.8|10.78| 17235452.0|10.78|000901|
|2019-01-15|10.93|10.65|10.76|10.93| 22737838.0|10.93|000901|
|2019-01-14| 4.76|  4.5| 4.76| 4.62| 47091306.0| 4.62|002288|
|2019-01-15| 4.62| 4.43| 4.61| 4.53| 41605808.0| 4.53|002288|
|2019-01-14| 13.2|12.55| 13.2|12.64| 20379017.0|12.64|002383|
|2019-01-15|13.06|12.73|12.75|12.87| 13656687.0|12.87|002383|
+----------+-----+-----+-----+-----+-----------+-----+------+
only showing top 20 rows


scala> //csv_data.createOrReplaceTempView("history_day")

scala> //sqlContext.sql("insert into table stock_dev.day_history select * from history_day")

scala> 

scala> //csv_data.toDF().insertInto("day_history")

scala> 

scala> 

scala> :quit
